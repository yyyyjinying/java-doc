# NoSQL数据库
memcache:简单的key-value模式,数据都在内存中，一般不持久化;
redis介绍:数据都在内存中，支持持久化，主要用作备份恢复,除了支持简单的key-value模式，还支持多种数据结构的存储，比如 list、set、hash、zset等,一般是作为缓存数据库辅助持久化的数据库,现在市面上用得非常多的一款内存数据库
mongoDB介绍: 高性能、开源、模式自由(schema free)的文档型数据库;数据都在内存中， 如果内存不足，把不常用的数据保存到硬盘;虽然是key-value模式，但是对value（尤其是json）提供了丰富的查询功能;支持二进制数据及大型对象;可以根据数据的特点替代RDBMS，成为独立的数据库。或者配合RDBMS，存储特定的数据。
列式存储HBase介绍:HBase是Hadoop项目中的数据库。它用于需要对大量的数据进行随机、实时读写操作的场景中。HBase的目标就是处理数据量非常庞大的表，可以用普通的计算机处理超过10亿行数据，还可处理有数百万列元素的数据表。

Redis是当前比较热门的NoSQL系统之一
它是一个开源的、使用ANSI C语言编写的key-value存储系统（区别于MySQL的二维表格形式存储）
和Memcache类似，但很大程度补偿了Memcache的不足，Redis数据都是缓存在计算机内存中，不同的是，Memcache只能将数据缓存到内存中，无法自动定期写入硬盘，这就表示，一断电或重启，内存清空，数据丢失;
稳定性：持久化，主从复制（集群）;其他特性：支持过期时间，支持事务，消息订阅
原子性 (主逻辑线程是单线程),Redis的所有操作都是原子性的，同时Redis还支持对几个操作全并后的原子性执行。 pipline;Redis读取的速度是30w次/s，写的速度是10w次/s
# Redis的应用场景
数据基本操作和详细信息：http://www.redis.cn/topics/data-types-intro.html#hashes
# string操作
1 设置值 获取值
set ydlclass value
get ydlclass
2 mset mget 一次性操作多组数据
mset ydlclass value ydlclass1 value1 ydlclass2 value2
mget ydlclass ydlclass1 ydlclass2
3 没有这个键我们才设置
setnx dlclass value
4 将key的值 加一，减一
incr stock 
decr stock
5设置 a值存活时间5秒，值是b    验证码
setex a 5 b
查看key的长度
strlen keyname 
set key some-value
expire key 5
set zhao 100 ex 10
ttl zhao
# hash
Hashes,由field和关联的value组成的map。field和value都是字符串的。
hmset user:1000 username antirez birthyear 1977 verified 1
hmget user:1000 username verified
hget user:1000 username
hgetall user:1000
hincrby user:1000 birthyear 10
小的 hash 被用特殊方式编码，非常节约内存
hset user username itlils
hset user age 18
hget user username
hkeys  user
Hvals user
hdel user:1000 username

# Lists
 按插入顺序排序的字符串元素的集合。他们基本上就是链表（linked lists）。列表就是有序元素的序列：10,20,1,2,3就是一个列表。但用数组实现的List和用Linked List实现的List，在属性方面大不相同。Redis lists基于Linked Lists实现。这意味着即使在一个list中有数百万个元素，在头部或尾部添加一个元素的操作，其时间复杂度也是常数级别的。用LPUSH 命令在十个元素的list头部添加新元素，和在千万元素list头部添加新元素的速度相同。
那么，坏消息是什么？在数组实现的list中利用索引访问元素的速度极快，而同样的操作在linked list实现的list上没有那么快。Redis Lists用linked list实现的原因是：对于数据库系统来说，至关重要的特性是：能非常快的在很大的列表上添加元素。另一个重要因素是，正如你将要看到的：Redis lists能在常数时间取得常数长度。如果快速访问集合元素很重要，建议使用可排序集合(sorted sets)。
list可被用来实现聊天系统。还可以作为不同进程间传递消息的队列。
List上的阻塞操作:brpop list 10  10秒后取值
三条规则来概括它的行为：
当我们向一个聚合数据类型中添加元素时，如果目标键不存在，就在添加元素前创建空的聚合数据类型。当我们从聚合数据类型中移除元素时，如果值仍然是空的，键自动被销毁。对一个空的 key 调用一个只读的命令，比如 LLEN （返回 list 的长度），或者一个删除元素的命令，将总是产生同样的结果。该结果和对一个空的聚合类型做同个操作的结果是一样的。
1 设置值
lpush list1 1 2 3 4 1
rpush list1 6
2查看数据
lrange list1 0 -1
lindex lists 0
3 移除数据
lpop list1
rpop list1
# Sets
不重复且无序的字符串元素的集合。Redis Set 是 String 的无序排列。SADD 指令把新的元素添加到 set 中。对 set 也可做一些其他的操作，比如测试一个给定的元素是否存在，对不同 set 取交集，并集或差，
sadd myset 1 2 3 4 4 4 5 6
smembers myset
sismember myset 1
sadd news:1000:tags 1 2 5 77
使用一个 set 把 标签tag ID 和新闻条目关联起来：
scard myset 获取成员数量
4业务 uv 当天登陆用户数
sadd uv:20220222 001 002 003 002
spop myset
# Sorted sets
类似Sets,但是每个字符串元素都关联到一个叫score浮动数值（floating number value）。里面的元素总是通过score进行着排序，所以不同的是，它是可以检索的一系列元素。它用来保存需要排序的数据，例如排行榜，一个班的语文成绩，一个公司的员工工资，一个论坛的帖子等。有序集合中，每个元素都带有score（权重），以此来对元素进行排序;它有三个元素：key、member和score。以语文成绩为例，key是考试名称（期中考试、期末考试等），member是学生名字，score是成绩。
1添加: zadd pv 100 page1.html 200 page2.html 300 page3.html
2查看: zcard pv
3查询指定权重范围的成员数: ZCOUNT pv 150 500
4增加权重: ZINCRBY pv 1 page1.html
5交集: ZADD pv_zset1 10 page1.html 20  page2.html
ZADD pv_zset2 5 page1.html 10  page2.html
ZINTERSTORE pv_zset_result 2 pv_zset1  pv_zset2
6成员的分数值: ZSCORE pv_zset page3.html   
7 获取下标范围内的成员。 排序，默认权重由低到高
ZRANGE pv 0 -1
8获取由高到低的几个成员（reverse）使用最多的
效率很高，因为本身zset就是排好序的。
ZREVRANGE key start stop
# key
del user1 
keys *     生产环境下，别用
exists user1
expire ydlclass 5
5剩余存活时间   登陆续期
pttl user1
6随机获取 key
randomkey
type keyname 查看类型
expire ydlclass 5
# 对HyperLogLog结构的操作
HyperLogLog常用于大数据量的统计，比如页面访问量统计或者用户访问量统计。(无法获取具体值)
HyperLogLog为什么适合做大量数据的统计
Redis HyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定的、并且是很小的。
在 Redis 里面，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基数。这和计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。但是，因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。
什么是基数？比如：数据集{1, 3, 5, 7, 5, 7, 8}，那么这个数据集的基数集{1, 3, 5, 7, 8}，基数（不重复元素）为5。基数估计就是在误差可接受的范围内，快速计算基数。
pfadd uv user1
pfcount uv
# 对位图BitMaps的操作
计算机最小的存储单位是位bit，Bitmaps是针对位的操作的，相较于String、Hash、Set等存储方式更加节省空间;Bitmaps不是一种数据结构，操作是基于String结构的，一个String最大可以存储512M，那么一个Bitmaps则可以设置2^32个位;Bitmaps单独提供了一套命令，所以在Redis中使用Bitmaps和使用字符串的方法不太相同。可以把Bitmaps想象成`一个以位为单位的数组`，数组的每个单元`只能存储0和1`，数组的下标在Bitmaps中叫做偏移量offset;BitMaps 命令说明：将每个独立用户是否访问过网站存放在Bitmaps中， 将访问的用户记做1， 没有访问的用户记做0， 用偏移量作为用户的id 。
setbit unique:users:2022-04-05 0 1
getbit unique:users:2022-04-05 0
bitcount unique:users:2022-04-05 0 -1

# Redis的持久化
由于redis是一个内存数据库，所有的数据都是保存在内存当中的，内存当中的数据极易丢失，所以redis的数据持久化就显得尤为重要，在redis当中，提供了两种数据持久化的方式，分别为RDB以及AOF，且Redis默认开启的数据持久化方式为RDB方式。
Redis会定期`保存数据快照至一个rbd文件`中，并在启动时自动加载rdb文件，恢复之前保存的数据。
save  60 100
save  600 500
每60秒检查一次数据变更情况，如果发生了100次或以上的数据变更，则进行RDB快照保存。
可以配置多条save指令，让Redis执行多级的快照保存策略；
手动触发RDB快照保存：SAVE或者BGSAVE命令；SAVE： 直接调用 rdbSave ，阻塞 Redis 主进程，直到保存完成为止；在主进程阻塞期间，服务器不能处理客户端的任何请求。BGSAVE 则 fork 出一个子进程，子进程负责调用 rdbSave ，并在保存完成之后向主进程发送信号，通知保存已完成。 Redis 服务器在BGSAVE 执行期间仍然可以继续处理客户端的请求。
# RDB方案优点
1.对性能影响最小。如前文所述，Redis在保存RDB快照时会fork出子进程进行，几乎不影响Redis处理客户端请求的效率。2.每次快照会生成一个完整的数据快照文件，所以可以辅以其他手段保存多个时间点的快照（例如把每天0点的快照备份至其他存储媒介中），作为非常可靠的灾难恢复手段。3.使用RDB文件进行数据恢复比使用AOF要快很多。
RDB方案缺点
快照是定期生成的，所以在Redis crash时或多或少会丢失一部分数据；如果数据集非常大且CPU不够强（比如单核CPU），Redis在fork子进程时可能会消耗相对较长的时间，影响Redis对外提供服务的能力

# AOF持久化方案
采用AOF持久方式时，Redis会把每一个写请求都记录在一个日志文件里。在Redis重启时，会把AOF文件中记录的所有`写操作顺序执`行一遍，确保数据恢复到最新。
appendonly  yes 
# appendfsync always:  每写入一条日志就进行一次fsync操作，数据安全性最高，但速度最慢
appendfsync everysec : 折中的做法，交由后台线程每秒fsync一次
# appendfsync no:  不进行fsync，将flush文件的时机交给OS决定，速度最快
AOF rewrite
随着AOF不断地记录写操作日志，因为所有的写操作都会记录，所以必定会出现一些无用的日志。大量无用的日志会让AOF文件过大，也会让数据恢复的时间过长。不过Redis提供了AOF rewrite功能，可以重写AOF文件，只保留能够把数据恢复到最新状态的最小写操作集。
auto-aof-rewrite-percentage 100  
auto-aof-rewrite-min-size 64mb  
此基本大小与当前大小进行比较。如果当前大小为 #大于指定的百分比，则触发重写。你需要为AOF文件指定一个要重写的最小大小;
# AOF优点
1.最安全，在启用appendfsync为always时，任何已写入的数据都不会丢失，使用在启用appendfsync everysec也至多只会丢失1秒的数据;2.AOF文件在发生断电等问题时也不会损坏，即使出现了某条日志只写入了一半的情况，也可以使用redis-check-aof工具轻松修复;3.AOF文件易读，可修改，在进行某些错误的数据清除操作后，只要AOF文件没有rewrite，就可以把AOF文件备份出来，把错误的命令删除，然后恢复数据。
# AOF的缺点
1.AOF文件通常比RDB文件更大;2.性能消耗比RDB高;3.数据恢复速度比RDB慢;
Redis的数据持久化工作本身就会带来延迟，需要根据数据的安全级别和性能要求制定合理的持久化策略：
AOF + fsync always的设置虽然能够绝对确保数据安全，但每个操作都会触发一次fsync，会对Redis的性能有比较明显的影响
AOF + fsync every second是比较好的折中方案，每秒fsync一次
AOF + fsync never会提供AOF持久化方案下的最优性能
# RDB or AOF
每一次RDB快照和AOF Rewrite都需要Redis主进程进行fork操作。fork操作本身可能会产生较高的耗时，与CPU和Redis占用的内存大小有关。根据具体的情况合理配置RDB快照和AOF Rewrite时机，避免过于频繁的fork带来的延迟。
Redis在fork子进程时需要将内存分页表拷贝至子进程，以占用了24GB内存的Redis实例为例，共需要拷贝48MB的数据。在使用单Xeon 2.27Ghz的物理机上，这一fork操作耗时216ms。
本人以前的公司，最后的从机上，rdb aof都开启。
# Redis 事务
Redis 事务的本质是一组命令的集合。事务支持一次执行多个命令，一个事务中所有命令都会被序列化。在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。总结：Redis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令;
Redis事务没有隔离级别的概念：批量操作在发送 EXEC 命令前被放入队列缓存，并不会被实际执行，也就不存在事务内的查询要看到事务里的更新，事务外查询不能看到；
Redis不保证原子性：Redis中，单条命令是原子性执行的，但事务不保证原子性，且没有回滚。`事务中任意命令执行失败，其余的命令仍会被执行`；
个事务从开始到执行会经历以下三个阶段：
第一阶段：开始事务;第二阶段：命令入队;第三阶段：执行事务
Redis事务相关命令：MULTI:开启事务，redis会将后续的命令逐个放入队列中，然后使用EXEC命令来原子化执行这个命令队列
EXEC: 执行事务中的所有操作命令
DISCARD: 取消事务，放弃执行事务块中的所有命令
WATCH: 监视一个或多个key，如果事务在执行前，这个key（或多个key）被其他命令修改，则事务被中断，不会执行事务中的任何命令
UNWATCH: 取消WATCH对所有key的监视
1.事务失败处理：语法错误（编译器错误），在开启事务后，修改k1值为11，k2值为22，但k2语法错误，最终导致事务提交失败，k1、k2保留原值。
2.Redis类型错误（运行时错误），在开启事务后，修改k1值为11，k2值为22，但将k2的类型作为List，在运行时检测类型错误，最终导致事务提交失败，此时事务并没有回滚，而是跳过错误命令继续执行， 结果k1值改变、k2保留原值。
为什么Redis不支持事务回滚？
多数事务失败是由语法错误或者数据结构类型错误导致的，语法错误说明在命令入队前就进行检测的，而类型错误是在执行时检测的，Redis为提升性能而采用这种简单的事务，这是不同于关系型数据库的，特别要注意区分。Redis之所以保持这样简易的事务，完全是为了保证高并发下的核心问题——性能。
# 数据删除与淘汰策略
内存中的数据可以通过TTL指令获取其状态TTL返回的值有三种情况：正数，-1，-2
正数：代表该数据在内存中还能存活的时间; -1：永久有效的数据; -2 ：已经过期的数据 或被删除的数据 或 未定义的数据;
`过期数据是一块独立的存储空间`，Hash结构，field是内存地址，value是过期时间，保存了所有key的过期描述，在最终进行过期处理的时候，对该空间的数据进行检测， 当时间到期之后通过field找到内存该地址处的数据，然后进行相关操作
# 数据删除策略
在内存占用与CPU占用之间寻找一种平衡，顾此失彼都会造成整体redis性能的下降，甚至引发服务器宕机或 内存泄露
1.定时删除
创建一个定时器，当key设置有过期时间，且过期时间到达时，由定时器任务立即执行对键的删除操作;优点：节约内存，到时就删除，快速释放掉不必要的内存占用;缺点：CPU压力很大，无论CPU此时负载量多高，均占用CPU，会影响redis服务器响应时间和指令吞吐量
总结：用处理器性能换取存储空间（拿时间换空间）
2.惰性删除
数据到达过期时间，不做处理。等下次访问该数据时，如果未过期，返回数据,发现已过期，删除，返回不存在;优点：节约CPU性能，发现必须删除的时候才删除;缺点：内存压力很大，出现长期占用内存的数据;总结：用存储空间换取处理器性能（拿时间换空间）
2.定期删除
周期性轮询redis库中的时效性数据，采用随机抽取的策略，利用过期数据占比的方式控制删除频度;特点1：CPU性能占用设置有峰值，检测频度可自定义设置;特点2：内存压力不是很大，长期占用内存的冷数据会被持续清理;总结：周期性抽查存储空间（随机抽查，重点抽查;
内存定期随机清理;每秒花费固定的CPU资源维护内存;随机抽查，重点抽查
# 淘汰策略
当新数据进入redis时，如果内存不足怎么办？在执行每一个命令前，会调用**freeMemoryIfNeeded()**检测内存是否充足。如果内存不满足新 加入数据的最低存储要求，redis要临时删除一些数据为当前指令清理存储空间。清理数据的策略称为逐出算法;
策略配置:
1.最大可使用内存，即占用物理内存的比例，默认值为0，表示不限制。生产环境中根据需求设定，通常设置在50%以上;maxmemory ?mb
每次选取待删除数据的个数，采用随机获取数据的方式作为待检测删除数据;maxmemory-samples count
对数据进行删除的选择策略 maxmemory-policy policy
maxmemory-policy volatile-lru
# 数据删除的策略policy到底有几种呢？一共是3类8种
第一类：检测易失数据(可能会过期的数据集server.db[i].expires ),同一个库
volatile-lru：挑选最近最少使用的数据淘汰      least recently used
volatile-lfu：挑选最近使用次数最少的数据淘汰   least frequently used
volatile-ttl：挑选将要过期的数据淘汰
volatile-random：任意选择数据淘汰
第二类：检测全库数据（所有数据集server.db[i].dict ）
allkeys-lru：挑选最近最少使用的数据淘汰
allkeLyRs-lfu：：挑选最近使用次数最少的数据淘汰
allkeys-random：任意选择数据淘汰，相当于随机
第三类：放弃数据驱逐
no-enviction（驱逐）：禁止驱逐数据(redis4.0中默认策略)，会引发OOM(Out Of Memory)

# 我们可以直接用 redis-cli 的 pipe执行我们的第一个大量数据插入命令
我们可以直接用 redis-cli 的 pipe执行我们的第一个大量数据插入命令，
# 尽可能使用散列表（hashes）
小散列表（是说散列表里面存储的数少）使用的内存非常小，所以你应该尽可能的将你的数据模型抽象到一个散列表里面。比如你的web系统中有一个用户对象，不要为这个用户的名称，姓氏，邮箱，密码设置单独的key,而是应该把这个用户的所有信息存储到一张散列表里面.使用散列结构高效存储抽象的键值对
# 内存分配
当某些缓存被删除后Redis并不是总是立即将内存归还给操作系统。这并不是redis所特有的，而是函数malloc()的特性。例如你缓存了5G的数据，然后删除了2G数据，从操作系统看，redis可能仍然占用了5G的内存（这个内存叫RSS,后面会用到这个概念）；内存分配器是智能的，可以复用用户已经释放的内存。redis的peak内存非常高于平时的内存使用时，碎片所占可用内存的比例就会波动很大；
如果 maxmemory 没有设置，redis就会一直向OS（操作系统）申请内存，直到OS的所有内存都被使用完。所以通常建议设置上redis的内存限制；设置了maxmemory后，当redis的内存达到内存限制后，再向redis发送写指令，会返回一个内存耗尽的错误。错误通常会触发一个应用程序错误，但是不会导致整台机器宕掉.
# Keys的过期时间
通常Redis keys创建时没有设置相关过期时间。他们会一直存在，除非使用显示的命令移除，例如，使用DEL命令。EXPIRE一类命令能关联到一个有额外内存开销的key。当key执行过期操作时，Redis会确保按照规定时间删除他们。key的过期时间和永久有效性可以通过EXPIRE和PERSIST命令（或者其他相关命令）来进行更新或者删除过期时间。
# 过期精度
在 Redis 2.4 及以前版本，过期期时间可能不是十分准确，有0-1秒的误差。从 Redis 2.6 起，过期时间误差缩小到0-1毫秒。
# 过期和持久
Keys的过期时间使用Unix时间戳存储(从Redis 2.6开始以毫秒为单位)。这意味着即使# Redis实例不可用，时间也是一直在流逝的。要想过期的工作处理好，计算机必须采用稳定的时间。 如果你将RDB文件在两台时钟不同步的电脑间同步，有趣的事会发生（所有的 keys装载时就会过期）。即使正在运行的实例也会检查计算机的时钟，例如如果你设置了一个key的有效期是1000秒，然后设置你的计算机时间为未来2000秒，这时key会立即失效，而不是等1000秒之后。
# Redis如何淘汰过期的keys
Redis keys过期有两种方式：被动和主动方式。
当一些客户端尝试访问它时，key会被发现并主动的过期。当然，这样是不够的，因为有些过期的keys，永远不会访问他们。 无论如何，这些keys应该过期，所以定时随机测试设置keys的过期时间。所有这些过期的keys将会从密钥空间删除。
具体就是Redis每秒10次做的事情：
测试随机的20个keys进行相关过期检测。
删除所有已经过期的keys。
如果有多于25%的keys过期，重复步奏1.
这是一个平凡的概率算法，基本上的假设是，我们的样本是这个密钥控件，并且我们不断重复过期检测，直到过期的keys的百分百低于25%,这意味着，在任何给定的时刻，最多会清除1/4的过期keys
不断重复过期检测，直到过期的keys的百分百低于25%,这意味着，在任何给定的时刻，最多会清除1/4的过期keys。
# 在复制AOF文件时如何处理过期
为了获得正确的行为而不牺牲一致性，当一个key过期，DEL将会随着AOF文字一起合成到所有附加的slaves。在master实例中，这种方法是集中的，并且不存在一致性错误的机会。然而，当slaves连接到master时，不会独立过期keys（会等到master执行DEL命令），他们任然会在数据集里面存在，所以当slave当选为master时淘汰keys会独立执行，然后成为master。
# Redis 脚本和事务
从定义上来说， Redis 中的脚本本身就是一种事务， 所以任何在事务里可以完成的事， 在脚本里面也能完成。 并且一般来说， 使用脚本要来得更简单，并且速度更快。因为脚本功能是 Redis 2.6 才引入的， 而事务功能则更早之前就存在了， 所以 Redis 才会同时存在两种处理事务的方法。不过我们并不打算在短时间内就移除事务功能， 因为事务提供了一种即使不使用脚本， 也可以避免竞争条件的方法， 而且事务本身的实现并不复杂。
不过在不远的将来， 可能所有用户都会只使用脚本来实现事务也说不定。 如果真的发生这种情况的话， 那么我们将废弃并最终移除事务功能。
# 3个特性就可以实现一个最低保障的分布式锁
1.安全属性（Safety property）: 独享（相互排斥）。在任意一个时刻，只有一个客户端持有锁。
2.活性A(Liveness property A): 无死锁。即便持有锁的客户端崩溃（crashed)或者网络被分裂（gets partitioned)，锁仍然可以被获取。
3.活性B(Liveness property B): 容错。 只要大部分Redis节点都活着，客户端就可以获取和释放锁.
# Redis主从复制
主从复制：主节点负责写数据，从节点负责读数据，主节点定期把数据同步到从节点保证数据的一致性
建立主从复制：slaveof 192.168.152.128 6379
断开主从复制：slaveof no one
# Redis主从拓扑
一主一从：用于主节点故障转移从节点，当主节点的“写”命令并发高且需要持久化，可以只在从节点开启AOF（主节点不需要），这样即保证了数据的安全性，也避免持久化对主节点的影响
一主多从：针对“读”较多的场景，“读”由多个从节点来分担，但节点越多，主节点同步到多节点的次数也越多，影响带宽，也加重主节点的稳定
树状主从：一主多从的缺点（主节点推送次数多压力大）可用些方案解决，主节点只推送一次数据到从节点B，再由从节点B推送到C，减轻主节点推送的压力。

# Redis中的Sentinel架构
哨兵(sentinel) 是一个分布式系统，用于对主从结构中的每台服务器进行监控，当出现故障时通过投票机制选择新的master并将所有slave连接到新的master。
哨兵的作用：监控：监控master和slave，不断的检查master和slave是否正常运行；master存活检测、master与slave运行情况检测；通知（提醒）：当被监控的服务器出现问题时，向其他（哨兵间，客户端）发送通知；`自动故障转移`：断开master与slave连接，选取一个slave作为master，将其他slave连接新的master，并告知客户端新的服务器地址；
# 哨兵工作原理

穿透（无）：数据不存在，却一直请求，崩溃
击穿：对一个过期的 key 一直访问，崩溃
雪崩：短时间，对多个过期的 key 分别一直访问，崩溃

# 缓存预热
服务器启动后迅速宕机
问题排查：
1.请求数量较高，大量的请求过来之后都需要去从缓存中获取数据，但是缓存中又没有，此时从数据库中查找数据然后将数据再存入缓存，造成了短期内对redis的高强度操作从而导致问题;2.主从之间数据吞吐量较大，数据同步操作频度较高
缓存预热就是系统启动前，提前将相关的缓存数据直接加载到缓存系统。避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！
# 缓存雪崩
1.系统平稳运行过程中，忽然数据库连接量激增;2.应用服务器无法及时处理请求;3.大量408，500错误页面出现;4.客户反复刷新页面获取数据;5.数据库崩溃;6.应用服务器崩溃;7.重启应用服务器无效;8.Redis服务器崩溃;9.Redis集群崩溃;10.重启数据库后再次被瞬间流量放倒
问题排查：
在一个较短的时间内，缓存中较多的key集中过期;2.此周期内请求访问过期的数据，redis未命中，redis向数据库获取数据;3.数据库同时接收到大量的请求无法及时处理;4.数据库流量激增，数据库崩溃
1.更多的页面静态化处理
2.构建多级缓存架构;​ Nginx缓存+redis缓存+ehcache缓存;3.检测Mysql严重耗时业务进行优化;​ 对数据库的瓶颈排查：例如超时查询、耗时较高事务等;4.灾难预警机制;​ 监控redis服务器性能指标;​ CPU占用、CPU使用率;​ 内存容量;​ 查询平均响应时间;​ 线程数;
5.限流、降级;短时间范围内牺牲一些客户体验，限制一部分请求访问，降低应用服务器压力，待业务低速运转后再逐步放开访问
落地实践：
1.LRU与LFU切换;2.数据有效期策略调整;;​ 根据业务数据有效期进行分类错峰，A类90分钟，B类80分钟，C类70分钟;​ 过期时间使用固定时间+随机值的形式，稀释集中到期的key的数量;3.超热数据使用永久key;4.定期维护（自动+人工;​ 对即将过期数据做访问量分析，确认是否延时，配合访问量统计，做热点数据的延时
`缓存雪崩就是瞬间过期数据量太大，导致对数据库服务器造成压力。如能够有效避免过期时间集中，可以有效解决雪崩现象的 出现（约40%），配合其他策略一起使用，并监控服务器的运行数据，根据运行记录做快速调整。`
# 缓存击穿
2.数据库连接量瞬间激增;3.Redis服务器无大量key过期;4.Redis内存平稳，无波动;5.Redis服务器CPU正常;6.数据库崩溃
问题排查：
1.Redis中某个key过期，该key访问量巨大
2.多个数据请求从服务器直接压到Redis后，均未命中
3.Redis在短时间内发起了大量对数据库中同一数据的访问
总而言之就两点：单个key高热数据，key过期
解决：
2.现场调整、​ 监控访问量，对自然流量激增的数据延长过期时间或设置为永久性key；
3.后台刷新数据，​ 启动定时任务，高峰期来临之前，刷新数据有效期，确保不丢失
4.二级缓存 设置不同的失效时间，保障不会被同时淘汰就行
5.加锁 分布式锁，防止被击穿，但是要注意也是性能瓶颈，慎重！
总的来说：缓存击穿就是单个高热数据过期的瞬间，数据访问量较大，未命中redis后，发起了大量对同一数据的数据库访问，导致对数 据库服务器造成压力。应对策略应该在业务数据分析与预防方面进行，配合运行监控测试与即时调整策略，毕竟单个key的过 期监控难度较高，配合雪崩处理策略即可。
# 缓存穿透
1.Redis中大面积出现未命中；2.出现非正常URL访问
获取的数据在数据库中也不存在，数据库查询未得到对应数据
Redis获取到null数据未进行持久化，直接返回
下次此类数据到达重复上述过程
出现黑客攻击服务器

.缓存null；​ 对查询结果为null的数据进行缓存（长期使用，定期清理），设定短时限，例如30-60秒，最高5分钟；2.白名单策略；​ 提前预热各种分类数据id对应的bitmaps，id作为bitmaps的offset，相当于设置了数据白名单。当加载正常数据时放行，加载异常数据时直接拦截（效率偏低）；​ 使用布隆过滤器（有关布隆过滤器的命中问题对当前状况可以忽略）；2.实施监控；​ 实时监控redis命中率（业务正常范围时，通常会有一个波动值）与null数据的占比
​ 非活动时段波动：通常检测3-5倍，超过5倍纳入重点排查对象；​ 活动时段波动：通常检测10-50倍，超过50倍纳入重点排查对象；​ 根据倍数不同，启动不同的排查流程。然后使用黑名单进行防控（运营）
4.key加密
​问题出现后，临时启动防灾业务key，对key进行业务层传输加密服务，设定校验程序，过来的key校验；​ 例如每天随机分配60个加密串，挑选2到3个，混淆到页面数据id中，发现访问key不满足规则，驳回数据访问。
总的来说：缓存击穿是指访问了不存在的数据，跳过了合法数据的redis数据缓存阶段，每次访问数据库，导致对数据库服务器造成压力。通常此类数据的出现量是一个较低的值，当出现此类情况以毒攻毒，并及时报警。应对策略应该在临时预案防范方面多做文章。
无论是黑名单还是白名单，都是对整体系统的压力，警报解除后尽快移除。
# Redis的命名规范
使用统一的命名规范；一般使用业务名(或数据库名)为前缀，用冒号分隔，例如，业务名:表名:id。；例如：shop:usr:msg_code（电商:用户:验证码）；控制key名称的长度，不要使用过长的key；在保证语义清晰的情况下，尽量减少Key的长度。有些常用单词可使用缩写，例如，user缩写为u，messages缩写为msg。；名称中不要包含特殊字符
包含空格、单双引号以及其他转义字符
# 性能指标监控


# redis的事务
multi /`m^lti/
set key1 va1 进入了命令队列，
exec 等待 exec 命令后再全部执行
discard 代表取消事务,命令队列没有执行

## 事务
若在事务队列中存在`命令性错误`（类似于 java 编译性错误）getset 
k3， ERR unknown command, 则执行 EXEC 命令时，所有命令都不会执行;
若在事务队列中存在`语法性错误`（类似于 java 的 1/0 的运行时异常），ERR value is not an integer or out of range, 则执行 EXEC 命令时，其他正确命令会被执行，错误命令抛出异常。
## redis的乐观锁
watch key [key]
unwatch 放弃监视，这是取消所有的监视
一旦 watch 某个 key，则会一直监视这个 key，如果 key 发生了变化，就返回提示。
作用：在执行 multi 之前，先执行 watch key1 [key2]，可以监视一个(或多个) key ，如果在事务 exec 执行之前这个(或这些) key 被其他命令所改动，那么事务将被打断。

使用场景：很多人同时对一个值进行操作，一旦这个值被修改，且被其他人监听，则其他人无法修改这个值

## 问题:
在高并发场景：假设库存有 500 个商品，2000 个人进行秒杀购买(2000 个程序监听商品的 key)，假设 1999 人同时购买，其内部程序监听的商品数量为 500，最后一个人却已经购买成功，商品数量变为 499，则前面的事务被打断(监听的 500 数量)，导致 1999 人会购买失败，库存还有 499 个商品。
出现事务执行被打断；无法解决库存遗留问题
## 使用 LUA 脚本可解决（具体还有其他）
利用Redis的lua脚本的原子性：意思是`在执行脚本时，不会执行其他脚本或Redis命令`。这个语义类似于MULTI（开启事务）/EXEC（触发事务，一并执行事务中的所有命令）。从所有其他客户端的角度来看，脚本的效果要么仍然不可见，要么已经完成。很好的解决了多线程的并发问题；


# 多线程并发削峰
多线程 + redis队列（单线程，多个线程取不到同一个数据）
tomcat并发500
redis的并发量150万/秒
spring的异步执行注解支持
openResty
秒杀场景：
1. 上百万的用户同时下单，再下单的方法中，将下单请求用下单对象记录，并将其leftPush到redis的list队列中；
2. 同时，创建多线程方法消费队列信息，方法中执行rightPop取出下单对象，执行减库存、变更订单状态等；
3. 多线程可以削峰，但会产生超卖，可以使用redis队列的特性，首先保存固定的库存，每次rightPop取值如果能取到值就执行减库存等操作；
4. 当库存减为零时，通过判断rightPop有没有值，获取size()作为判断是否同步mysql数据库和同步redis订单；

总结秒杀场景的处理方案：
第一种方案：
1、Redis的decr进行lua脚本原子减操作，将库存减去1;
2、生成唯一订单号，将用户、商品、唯一订单号等信息，放入到队列中;
3、异步消耗redis队列，进行数据库层面的库存减1，生成订单信息;
第二种种方案：
1、Redis的decr和redis队列配合判断重复下单和解决超卖，每次rightPop取值如果能取到值就执行减库存等操作（前提是把所有的库存都提前存入队列中）;
2、生成唯一订单号，将用户、商品、唯一订单号等信息，放入到队列中;
3、异步消耗redis队列，进行数据库层面的库存减1，生成订单信息;






